{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409ca1d6-eaf8-47db-85f6-f37f32076cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ee93b7-f67e-469e-bcdc-eedc016ca4f5",
   "metadata": {},
   "source": [
    "## 1.1 Install dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967a60a-89c6-499f-93a5-045ae843d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c apple tensorflow-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f891dc-11f5-4b3a-9067-99976f00a0f6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m pip install tensorflow-macos tensorflow-metal opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21487d2e-774c-4101-97b7-95fecf39a807",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#upgrading the package\n",
    "!pip install numpy --upgrade \n",
    "!pip install pandas --upgrade \n",
    "!pip install matplotlib --upgrade \n",
    "!pip install scikit-learn --upgrade \n",
    "!pip install scipy --upgrade\n",
    "!pip install plotly --upgrade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e451a7-7eda-496e-a341-090ae8682591",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print a list of the all the packages \n",
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f1474-e69f-4121-8a51-b9f151898aae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import tensorflow\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3032e4-9219-4a42-b5ad-396146642eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check for available GPUs\n",
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379c5ac2-e8d9-4561-bcc3-4903d77b8803",
   "metadata": {},
   "source": [
    "## 1.2 Remove doggy images\n",
    "\n",
    "Imcompatible images needs to be removed from the mass images obtained from the web\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8078f6be-5a57-4749-86ac-64be5e5e1598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e495346d-fa2e-4fed-ad2c-0ef75d970e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the image directory\n",
    "data_dir = 'images_data'\n",
    "\n",
    "#set the desired image extension\n",
    "image_ext = ['jpeg','jpg','png','bmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10bc334-ac17-4357-a02b-c594d1961ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adda798-aac0-4738-9a3c-14673ed42403",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loops through the class of images\n",
    "for image_class in os.listdir(data_dir):\n",
    "    #loops through all the images in each class\n",
    "    for image in os.listdir(os.path.join(data_dir,image_class)):\n",
    "        image_path = os.path.join(data_dir,image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_ext:\n",
    "                print(f'Image not in ext list {image_path}')\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print(f'Issue with image {image_path}')\n",
    "            #os.remove(image_path)\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed1c87-7ae0-48ec-84e3-8ff28fdf6174",
   "metadata": {},
   "source": [
    "## 1.3 Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af945bce-6e4a-4703-ab8c-fb8af83c7397",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.data.Dataset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3989a270-19a4-422e-a979-f0d0bffaa9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data with keras utils\n",
    "#it reshapes the images and puts them in batches (default batch size =32)\n",
    "data = tf.keras.utils.image_dataset_from_directory('images_data') #this is still like an iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1313ec-ced2-4856-a0da-7cbdff9dec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the data into a numpy iterator\n",
    "data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f7d92f-cf59-411a-a32a-31ad8de5dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a batch of images\n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98af12d2-e022-4793-a3dd-44d37a2c520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0][31, 0, 0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d095b9-6462-4eff-a940-ffed1a074de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot sample images \n",
    "fig, ax = plt.subplots(ncols=5, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:5]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbdd90b-a336-46b1-80f0-51e719c8dccb",
   "metadata": {},
   "source": [
    "## 2 Preprocess the data\n",
    "### 2.1 Scale the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7540f-9aac-4f9d-8ba2-a54a86c8dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y : (x/255,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ac902f-cab5-4032-89f2-ebfff78e8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b335a1-5297-4d67-a4d4-928c2e44c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot sample images \n",
    "fig, ax = plt.subplots(ncols=5, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:5]):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a906a4-e3be-468b-888c-bbb7602a6a7e",
   "metadata": {},
   "source": [
    "### 2.2 Split the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0340fd96-242c-4764-b3a1-b64602af28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the number of batches\n",
    "data_length = len(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e66150f-1160-4256-9166-bfc41b9e7327",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(data_length *.7)\n",
    "val_size = int(data_length*.2)\n",
    "test_size = int(data_length*.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50666f37-d9f2-43bf-a73a-da0280786a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_size + val_size + test_size == data_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d3506d-1b91-4deb-8251-abecadc97048",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ebfa4-47d8-4310-9d58-6b68769c4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c070874-9970-4b27-ac31-0d59230ec806",
   "metadata": {},
   "source": [
    "## 3. Deep Learning\n",
    "### 3.1 Build the Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6bc1b8-7be2-4fe4-8b47-1de74f1afeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the needed libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b15d371-8c5b-4194-818b-8447ddea0085",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape =(256,256,3)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c6f7dc-783e-4c32-b5b1-df2ada9caba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#complile the model\n",
    "model.compile('adam', loss = tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb786507-2dd2-44fd-abcf-85fc1bb446ee",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9764cb94-0ed8-4b78-a9f6-bc2b0ef03e56",
   "metadata": {},
   "source": [
    "## 3.2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f746263-8640-41cf-9ff7-98f66ba208e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = 'logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9116f1-290b-4ce6-962a-683a75ccdc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a tensorboard cLLback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779179aa-ea28-48e5-b6f3-b504531a35bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "history = model.fit(train, epochs=20, validation_data = val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b8db0c-09bc-483d-98e4-4819c6cbdc2f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bf1495-7a2f-443c-bc25-839961bbae90",
   "metadata": {},
   "source": [
    "### 3.3 Plot the Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189c2020-017a-4092-bcef-8e9d09d92e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training loss and validation loss\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'], color ='blue', label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], color = 'red', label='Validation Loss')\n",
    "plt.suptitle('Loss Plot', fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b3d72-9468-45b3-9915-3cf387918ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training accuracy and validation accuracy\n",
    "fig = plt.figure()\n",
    "plt.plot(history.history['accuracy'], color ='blue', label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], color = 'red', label='Validation Accuracy')\n",
    "plt.suptitle('Accuracy Plot', fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a400b3f5-e96d-444c-a506-04aedccf1e9f",
   "metadata": {},
   "source": [
    "## 4. Evaluate Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97c023e-a42d-4178-8598-424e788f4ade",
   "metadata": {},
   "source": [
    "### 4.1 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7c8aae-0267-4c76-8102-bb05e51429cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e0a35-31f6-4263-b935-52005e91a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating the metrics\n",
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a3b33f-4f47-46a5-b73f-ca0aa22830a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    x, y = batch \n",
    "    y_pred = model.predict(x)\n",
    "    pre.update_state(y, y_pred)\n",
    "    re.update_state(y, y_pred)\n",
    "    acc.update_state(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7e9c46-a7ce-4228-b693-b7593ef9b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision: {pre.result()}, Recall: {re.result()}, Accuracy: {acc.result()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0bb3bb-3e71-4c7f-90dd-ea1c0d5251de",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = test.as_numpy_iterator().next()\n",
    "fig, ax = plt.subplots(ncols=5, figsize=(20,20))\n",
    "for i, image in enumerate(batch[0][:5]):\n",
    "    ax[i].imshow(image)\n",
    "    ax[i].title.set_text(batch[1][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd97cf-cd2b-46ef-affa-3494c695d016",
   "metadata": {},
   "source": [
    "### 4.2 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902d6b9e-6010-4add-ac47-e7342e98ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a random image not seen before by the classifer\n",
    "img = cv2.imread('Image 3.jpeg')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a53b3c-b5bd-4082-ab90-73e452d610e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the test data\n",
    "img_resized = tf.image.resize(img, (256,256))\n",
    "plt.imshow(img_resized.numpy().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e89a9ac-acef-4e2d-8fb0-8022e9d2e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(np.expand_dims(img_resized/255,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25bd72-2d61-4b1c-b14f-8187ba743f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd924a9b-a71d-4b76-a514-b037a63ee643",
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_pred < 0.5:\n",
    "    print('Predicted class is Happy!')\n",
    "else: print('Predicted class is Sad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ee00e8-94f2-40e5-ab2c-01475b0a0746",
   "metadata": {},
   "source": [
    "## 5. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1169875d-be54-451f-b81b-93f31ffca41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbe5555-b3d9-4797-9ba5-17a79d1d404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('happy_sad_imageclassificationmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e5694-8bd1-4c2d-ad8c-76f26906ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('happy_sad_imageclassificationmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c246059-fb88-42ed-9f50-7dedc10ac3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ed8e79-0d0b-4ae7-860b-23d9a2979e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pipreqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c1a001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageclassification",
   "language": "python",
   "name": "imageclassification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
